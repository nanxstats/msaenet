[{"path":[]},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others‚Äô private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement @nanx.. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://nanx.me/msaenet/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla‚Äôs code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://nanx.me/msaenet/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to msaenet","title":"Contributing to msaenet","text":"üëçüéâ First , thanks taking time contribute! üéâüëç contribute project : Filing bug report feature request issue. Suggesting change via pull request.","code":""},{"path":"https://nanx.me/msaenet/CONTRIBUTING.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"Contributing to msaenet","text":"file issue possible bug, please try include: Relevant package versions Necessary code data reproduce issue","code":""},{"path":"https://nanx.me/msaenet/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull Requests","title":"Contributing to msaenet","text":"suggest change via pull requests, please: Fork repository GitHub account. Clone forked repository local machine, make changes. Commit push changes GitHub. Create pull request.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright ¬© 2007 Free Software Foundation, Inc.¬†<http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program‚Äìmake sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers‚Äô authors‚Äô protection, GPL clearly explains warranty free software. users‚Äô authors‚Äô sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users‚Äô freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"‚ÄúLicense‚Äù refers version 3 GNU General Public License. ‚ÄúCopyright‚Äù also means copyright-like laws apply kinds works, semiconductor masks. ‚ÄúProgram‚Äù refers copyrightable work licensed License. licensee addressed ‚Äú‚Äù. ‚ÄúLicensees‚Äù ‚Äúrecipients‚Äù may individuals organizations. ‚Äúmodify‚Äù work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called ‚Äúmodified version‚Äù earlier work work ‚Äúbased ‚Äù earlier work. ‚Äúcovered work‚Äù means either unmodified Program work based Program. ‚Äúpropagate‚Äù work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. ‚Äúconvey‚Äù work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays ‚ÄúAppropriate Legal Notices‚Äù extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"‚Äúsource code‚Äù work means preferred form work making modifications . ‚ÄúObject code‚Äù means non-source form work. ‚ÄúStandard Interface‚Äù means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. ‚ÄúSystem Libraries‚Äù executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. ‚ÄúMajor Component‚Äù, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . ‚ÄúCorresponding Source‚Äù work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work‚Äôs System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users‚Äô Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work‚Äôs users, third parties‚Äô legal rights forbid circumvention technological measures.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program‚Äôs source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 ‚Äúkeep intact notices‚Äù. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called ‚Äúaggregate‚Äù compilation resulting copyright used limit access legal rights compilation‚Äôs users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. ‚ÄúUser Product‚Äù either (1) ‚Äúconsumer product‚Äù, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, ‚Äúnormally used‚Äù refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. ‚ÄúInstallation Information‚Äù User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"‚ÄúAdditional permissions‚Äù terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered ‚Äúrestrictions‚Äù within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. ‚Äúentity transaction‚Äù transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party‚Äôs predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"‚Äúcontributor‚Äù copyright holder authorizes use License Program work Program based. work thus licensed called contributor‚Äôs ‚Äúcontributor version‚Äù. contributor‚Äôs ‚Äúessential patent claims‚Äù patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, ‚Äúcontrol‚Äù includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor‚Äôs essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, ‚Äúpatent license‚Äù express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). ‚Äúgrant‚Äù patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. ‚ÄúKnowingly relying‚Äù means actual knowledge , patent license, conveying covered work country, recipient‚Äôs use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license ‚Äúdiscriminatory‚Äù include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others‚Äô Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License ‚Äúlater version‚Äù applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy‚Äôs public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM ‚Äú‚Äù WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://nanx.me/msaenet/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least ‚Äúcopyright‚Äù line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program‚Äôs commands might different; GUI interface, use ‚Äúbox‚Äù. also get employer (work programmer) school, , sign ‚Äúcopyright disclaimer‚Äù program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://nanx.me/msaenet/articles/msaenet.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"A Quick Introduction to msaenet","text":"msaenet package implemented multi-step adaptive elastic-net method introduced Xiao Xu (2015) feature selection high-dimensional regressions.","code":""},{"path":"https://nanx.me/msaenet/articles/msaenet.html","id":"walkthrough","dir":"Articles","previous_headings":"","what":"Walkthrough","title":"A Quick Introduction to msaenet","text":"Let‚Äôs load package: First, generate simulated data setting often used testing high-dimensional linear models, function msaenet.sim.gaussian(): parameter rho controls degree correlation among variables. coef sets coefficients ‚Äútrue‚Äù variables, case, first 10 variables coefficient 1 490 variables coefficient 0. snr represents designated signal--noise ratio (SNR) simulated data. parameter p.train decides proportion training set (relative total number observations n). generate simulation data types generalized linear models supported msaenet, simply use msaenet.sim.binomial() (logistic regression), msaenet.sim.cox() (Cox regression), msaenet.sim.poisson() (Poisson regression). returned object dat contains training test set. use training set modeling (parameter tuning model fitting), evaluate model‚Äôs performance test set independently. parameter alphas sets alpha tuning grid elastic-net adaptive estimation steps. nsteps indicates many adaptive estimation steps used. default, internal parameter tuning done k-fold cross-validation, parameters produce minimum prediction errors selected. also set parallel = TRUE run calling function make parameter tuning run parallel. probably save time alphas grid denser data size larger. select optimal model estimation step different criterion, use argument tune. Options include \"cv\" (k-fold cross-validation, default), \"aic\" (AIC), \"bic\" (BIC), \"ebic\" (Extened BIC). Similarly, use tune.nsteps specify criterion selecting optimal estimation step (optimal model steps), options include \"max\" (select final-step, default), \"aic\", \"bic\", \"ebic\". Let‚Äôs inspect fitted model, looking best step selected variables (variables non-zero coefficients), number false positive selections/true positive selections: Next, make predictions test set using fitted model, compute evaluation metrics, RMSE MAE: coefficient plot shows coefficient changes variables across every adaptive estimation step:  y-axis plot represents relative effect size estimations (standardized [0, 1]) variables. Plot change information criterion (EBIC ) used select optimal step:  Create Cleveland dot plot model coefficients optimal step:  plot absolute values coefficients instead raw coefficients, use abs = TRUE. vanilla adaptive elastic-net (Zou Zhang 2009) implemented function aenet(). multi-step adaptive estimation based MCP-net SCAD-net, see ?amnet, ?asnet, ?msamnet, ?msasnet details. analyses apply models fitted functions well.","code":"library(\"msaenet\") dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.5,   coef = rep(1, 10), snr = 5, p.train = 0.7,   seed = 1001 ) msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.1, 0.9, 0.1),   nsteps = 10L, tune.nsteps = \"ebic\",   seed = 1005 ) library(\"doParallel\") registerDoParallel(detectCores()) msaenet.fit$best.step #> [1] 6 msaenet.nzv(msaenet.fit) #>  [1]   2   3   4   6   7   9  10  35 363 379 msaenet.nzv.all(msaenet.fit) #> [[1]] #>  [1]   1   2   3   4   5   6   7   8   9  10  22  33  35  47 124 183 191 225 266 #> [20] 269 312 325 334 363 379 388 396 449 #>  #> [[2]] #>  [1]   1   2   3   4   5   6   7   8   9  10  35 269 363 379 #>  #> [[3]] #>  [1]   2   3   4   5   6   7   8   9  10  35 269 363 379 #>  #> [[4]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[5]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[6]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[7]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[8]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[9]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[10]] #>  [1]   2   3   4   6   7   9  10  35 363 379 #>  #> [[11]] #>  [1]   2   3   4   6   7   9  10  35 363 379 msaenet.fp(msaenet.fit, 1:10) #> [1] 3 msaenet.tp(msaenet.fit, 1:10) #> [1] 7 msaenet.pred <- predict(msaenet.fit, dat$x.te) msaenet.rmse(dat$y.te, msaenet.pred) #> [1] 2.638096 msaenet.mae(dat$y.te, msaenet.pred) #> [1] 2.172675 plot(msaenet.fit, label = TRUE) plot(msaenet.fit, type = \"criterion\") plot(msaenet.fit, type = \"dotplot\", label = TRUE, label.cex = 1)"},{"path":"https://nanx.me/msaenet/articles/msaenet.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"A Quick Introduction to msaenet","text":"used msaenet research, please feel free cite paper (Xiao Xu 2015) publications. questions bug report, please email create issue GitHub.","code":""},{"path":[]},{"path":"https://nanx.me/msaenet/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nan Xiao. Author, maintainer. Qing-Song Xu. Author.","code":""},{"path":"https://nanx.me/msaenet/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Nan Xiao Qing-Song Xu. (2015). Multi-step adaptive elastic-net: reducing false positives high-dimensional variable selection. Journal Statistical Computation Simulation 85(18), 3755-3765.","code":"@Article{,   title = {Multi-step adaptive elastic-net: reducing false positives in high-dimensional variable selection},   author = {Nan Xiao and Qing-Song Xu},   journal = {Journal of Statistical Computation and Simulation},   volume = {85},   number = {18},   pages = {3755--3765},   year = {2015},   doi = {10.1080/00949655.2015.1016944}, }"},{"path":"https://nanx.me/msaenet/index.html","id":"msaenet-","dir":"","previous_headings":"","what":"Multi-Step Adaptive Estimation Methods for Sparse Regressions","title":"Multi-Step Adaptive Estimation Methods for Sparse Regressions","text":"msaenet implements multi-step adaptive elastic-net (MSAENet) algorithm feature selection high-dimensional regressions proposed Xiao Xu (2015) [PDF]. Nonconvex multi-step adaptive estimations based MCP-net SCAD-net also supported. Check vignette(\"msaenet\") get started.","code":""},{"path":"https://nanx.me/msaenet/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Multi-Step Adaptive Estimation Methods for Sparse Regressions","text":"can install msaenet CRAN: try development version GitHub:","code":"install.packages(\"msaenet\") remotes::install_github(\"nanxstats/msaenet\")"},{"path":"https://nanx.me/msaenet/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Multi-Step Adaptive Estimation Methods for Sparse Regressions","text":"cite msaenet package publications, please use Nan Xiao Qing-Song Xu. (2015). Multi-step adaptive elastic-net: reducing false positives high-dimensional variable selection. Journal Statistical Computation Simulation 85(18), 3755‚Äì3765. BibTeX entry LaTeX users ","code":"@article{,   title   = {Multi-step adaptive elastic-net: reducing false positives in high-dimensional variable selection},   author  = {Nan Xiao and Qing-Song Xu},   journal = {Journal of Statistical Computation and Simulation},   volume  = {85},   number  = {18},   pages   = {3755--3765},   year    = {2015},   doi     = {10.1080/00949655.2015.1016944} }"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://nanx.me/msaenet/index.html","id":"contribute","dir":"","previous_headings":"","what":"Contribute","title":"Multi-Step Adaptive Estimation Methods for Sparse Regressions","text":"contribute project, please take look Contributing Guidelines first. Please note msaenet project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://nanx.me/msaenet/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Multi-Step Adaptive Estimation Methods for Sparse Regressions","text":"msaenet free open source software, licensed GPL-3.","code":""},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive Elastic-Net ‚Äî aenet","title":"Adaptive Elastic-Net ‚Äî aenet","text":"Adaptive Elastic-Net","code":""},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive Elastic-Net ‚Äî aenet","text":"","code":"aenet(   x,   y,   family = c(\"gaussian\", \"binomial\", \"poisson\", \"cox\"),   init = c(\"enet\", \"ridge\"),   alphas = seq(0.05, 0.95, 0.05),   tune = c(\"cv\", \"ebic\", \"bic\", \"aic\"),   nfolds = 5L,   rule = c(\"lambda.min\", \"lambda.1se\"),   ebic.gamma = 1,   scale = 1,   lower.limits = -Inf,   upper.limits = Inf,   penalty.factor.init = rep(1, ncol(x)),   seed = 1001,   parallel = FALSE,   verbose = FALSE )"},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive Elastic-Net ‚Äî aenet","text":"x Data matrix. y Response vector family \"gaussian\", \"binomial\", \"poisson\". family \"cox\", response matrix created Surv. family Model family, can \"gaussian\", \"binomial\", \"poisson\", \"cox\". init Type penalty used initial estimation step. Can \"enet\" \"ridge\". alphas Vector candidate alphas use cv.glmnet. tune Parameter tuning method estimation step. Possible options \"cv\", \"ebic\", \"bic\", \"aic\". Default \"cv\". nfolds Fold numbers cross-validation tune = \"cv\". rule Lambda selection criterion tune = \"cv\", can \"lambda.min\" \"lambda.1se\". See cv.glmnet details. ebic.gamma Parameter Extended BIC penalizing size model space tune = \"ebic\", default 1. details, see Chen Chen (2008). scale Scaling factor adaptive weights: weights = coefficients^(-scale). lower.limits Lower limits coefficients. Default -Inf. details, see glmnet. upper.limits Upper limits coefficients. Default Inf. details, see glmnet. penalty.factor.init multiplicative factor penalty applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. make certain variables likely selected, assign smaller value. Default rep(1, ncol(x)). seed Random seed cross-validation fold division. parallel Logical. Enable parallel parameter tuning , default FALSE. enable parallel tuning, load doParallel package run registerDoParallel() number CPU cores calling function. verbose print estimation progress?","code":""},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adaptive Elastic-Net ‚Äî aenet","text":"List model coefficients, glmnet model object, optimal parameter set.","code":""},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adaptive Elastic-Net ‚Äî aenet","text":"Zou, Hui, Hao Helen Zhang. (2009). adaptive elastic-net diverging number parameters. Annals Statistics 37(4), 1733--1751.","code":""},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adaptive Elastic-Net ‚Äî aenet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/aenet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adaptive Elastic-Net ‚Äî aenet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  aenet.fit <- aenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2), seed = 1002 )  print(aenet.fit) #> Call: aenet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.2, 0.8, 0.2),  #>     seed = 1002)  #>   Df      %Dev       Lambda #> 1 12 0.7962207 9.644864e+14 msaenet.nzv(aenet.fit) #>  [1]   2   3   4   5  33  35  49 114 269 363 379 441 msaenet.fp(aenet.fit, 1:5) #> [1] 8 msaenet.tp(aenet.fit, 1:5) #> [1] 4 aenet.pred <- predict(aenet.fit, dat$x.te) msaenet.rmse(dat$y.te, aenet.pred) #> [1] 2.640474 plot(aenet.fit)"},{"path":"https://nanx.me/msaenet/reference/amnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive MCP-Net ‚Äî amnet","title":"Adaptive MCP-Net ‚Äî amnet","text":"Adaptive MCP-Net","code":""},{"path":"https://nanx.me/msaenet/reference/amnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive MCP-Net ‚Äî amnet","text":"","code":"amnet(   x,   y,   family = c(\"gaussian\", \"binomial\", \"poisson\", \"cox\"),   init = c(\"mnet\", \"ridge\"),   gammas = 3,   alphas = seq(0.05, 0.95, 0.05),   tune = c(\"cv\", \"ebic\", \"bic\", \"aic\"),   nfolds = 5L,   ebic.gamma = 1,   scale = 1,   eps = 1e-04,   max.iter = 10000L,   penalty.factor.init = rep(1, ncol(x)),   seed = 1001,   parallel = FALSE,   verbose = FALSE )"},{"path":"https://nanx.me/msaenet/reference/amnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive MCP-Net ‚Äî amnet","text":"x Data matrix. y Response vector family \"gaussian\", \"binomial\", \"poisson\". family \"cox\", response matrix created Surv. family Model family, can \"gaussian\", \"binomial\", \"poisson\", \"cox\". init Type penalty used initial estimation step. Can \"mnet\" \"ridge\". gammas Vector candidate gammas (concavity parameter) use MCP-Net. Default 3. alphas Vector candidate alphas use MCP-Net. tune Parameter tuning method estimation step. Possible options \"cv\", \"ebic\", \"bic\", \"aic\". Default \"cv\". nfolds Fold numbers cross-validation tune = \"cv\". ebic.gamma Parameter Extended BIC penalizing size model space tune = \"ebic\", default 1. details, see Chen Chen (2008). scale Scaling factor adaptive weights: weights = coefficients^(-scale). eps Convergence threshhold use MCP-net. max.iter Maximum number iterations use MCP-net. penalty.factor.init multiplicative factor penalty applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. make certain variables likely selected, assign smaller value. Default rep(1, ncol(x)). seed Random seed cross-validation fold division. parallel Logical. Enable parallel parameter tuning , default FALSE. enable parallel tuning, load doParallel package run registerDoParallel() number CPU cores calling function. verbose print estimation progress?","code":""},{"path":"https://nanx.me/msaenet/reference/amnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adaptive MCP-Net ‚Äî amnet","text":"List model coefficients, ncvreg model object, optimal parameter set.","code":""},{"path":"https://nanx.me/msaenet/reference/amnet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adaptive MCP-Net ‚Äî amnet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/amnet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adaptive MCP-Net ‚Äî amnet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  amnet.fit <- amnet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2), seed = 1002 )  print(amnet.fit) #> Call: amnet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.2, 0.8, 0.2),  #>     seed = 1002)  #>   Df    Lambda Gamma Alpha #> 1  5 0.2826344     3   0.8 msaenet.nzv(amnet.fit) #> [1]   2   4   5  35 269 msaenet.fp(amnet.fit, 1:5) #> [1] 2 msaenet.tp(amnet.fit, 1:5) #> [1] 3 amnet.pred <- predict(amnet.fit, dat$x.te) msaenet.rmse(dat$y.te, amnet.pred) #> [1] 2.672097 plot(amnet.fit)"},{"path":"https://nanx.me/msaenet/reference/asnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive SCAD-Net ‚Äî asnet","title":"Adaptive SCAD-Net ‚Äî asnet","text":"Adaptive SCAD-Net","code":""},{"path":"https://nanx.me/msaenet/reference/asnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive SCAD-Net ‚Äî asnet","text":"","code":"asnet(   x,   y,   family = c(\"gaussian\", \"binomial\", \"poisson\", \"cox\"),   init = c(\"snet\", \"ridge\"),   gammas = 3.7,   alphas = seq(0.05, 0.95, 0.05),   tune = c(\"cv\", \"ebic\", \"bic\", \"aic\"),   nfolds = 5L,   ebic.gamma = 1,   scale = 1,   eps = 1e-04,   max.iter = 10000L,   penalty.factor.init = rep(1, ncol(x)),   seed = 1001,   parallel = FALSE,   verbose = FALSE )"},{"path":"https://nanx.me/msaenet/reference/asnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive SCAD-Net ‚Äî asnet","text":"x Data matrix. y Response vector family \"gaussian\", \"binomial\", \"poisson\". family \"cox\", response matrix created Surv. family Model family, can \"gaussian\", \"binomial\", \"poisson\", \"cox\". init Type penalty used initial estimation step. Can \"snet\" \"ridge\". gammas Vector candidate gammas (concavity parameter) use SCAD-Net. Default 3.7. alphas Vector candidate alphas use SCAD-Net. tune Parameter tuning method estimation step. Possible options \"cv\", \"ebic\", \"bic\", \"aic\". Default \"cv\". nfolds Fold numbers cross-validation tune = \"cv\". ebic.gamma Parameter Extended BIC penalizing size model space tune = \"ebic\", default 1. details, see Chen Chen (2008). scale Scaling factor adaptive weights: weights = coefficients^(-scale). eps Convergence threshhold use SCAD-net. max.iter Maximum number iterations use SCAD-net. penalty.factor.init multiplicative factor penalty applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. make certain variables likely selected, assign smaller value. Default rep(1, ncol(x)). seed Random seed cross-validation fold division. parallel Logical. Enable parallel parameter tuning , default FALSE. enable parallel tuning, load doParallel package run registerDoParallel() number CPU cores calling function. verbose print estimation progress?","code":""},{"path":"https://nanx.me/msaenet/reference/asnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adaptive SCAD-Net ‚Äî asnet","text":"List model coefficients, ncvreg model object, optimal parameter set.","code":""},{"path":"https://nanx.me/msaenet/reference/asnet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adaptive SCAD-Net ‚Äî asnet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/asnet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adaptive SCAD-Net ‚Äî asnet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  asnet.fit <- asnet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2), seed = 1002 )  print(asnet.fit) #> Call: asnet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.2, 0.8, 0.2),  #>     seed = 1002)  #>   Df    Lambda Gamma Alpha #> 1  4 0.3104638   3.7   0.8 msaenet.nzv(asnet.fit) #> [1]  2  4  5 35 msaenet.fp(asnet.fit, 1:5) #> [1] 1 msaenet.tp(asnet.fit, 1:5) #> [1] 3 asnet.pred <- predict(asnet.fit, dat$x.te) msaenet.rmse(dat$y.te, asnet.pred) #> [1] 2.693865 plot(asnet.fit)"},{"path":"https://nanx.me/msaenet/reference/coef.msaenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Coefficients ‚Äî coef.msaenet","title":"Extract Model Coefficients ‚Äî coef.msaenet","text":"Extract model coefficients final model msaenet model objects.","code":""},{"path":"https://nanx.me/msaenet/reference/coef.msaenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Coefficients ‚Äî coef.msaenet","text":"","code":"# S3 method for msaenet coef(object, ...)"},{"path":"https://nanx.me/msaenet/reference/coef.msaenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Coefficients ‚Äî coef.msaenet","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet. ... Additional parameters coef (used).","code":""},{"path":"https://nanx.me/msaenet/reference/coef.msaenet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Coefficients ‚Äî coef.msaenet","text":"numerical vector model coefficients.","code":""},{"path":"https://nanx.me/msaenet/reference/coef.msaenet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Model Coefficients ‚Äî coef.msaenet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/coef.msaenet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Model Coefficients ‚Äî coef.msaenet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  coef(msaenet.fit) #>   [1]  0.0000000  2.1657439  0.0000000  1.7619827  0.8366843  0.0000000 #>   [7]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [13]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [19]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [25]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [31]  0.0000000  0.0000000  0.0000000  0.0000000  0.8954118  0.0000000 #>  [37]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [43]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [49]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [55]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [61]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [67]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [73]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [79]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [85]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [91]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #>  [97]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [103]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [109]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 -0.3592967 #> [115]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [121]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [127]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [133]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [139]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [145]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [151]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [157]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [163]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [169]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [175]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [181]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [187]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [193]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [199]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [205]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [211]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [217]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [223]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [229]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [235]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [241]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [247]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [253]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [259]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [265]  0.0000000  0.0000000  0.0000000  0.0000000  0.7274414  0.0000000 #> [271]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [277]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [283]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [289]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [295]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [301]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [307]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [313]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [319]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [325]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [331]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [337]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [343]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [349]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [355]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [361]  0.0000000  0.0000000 -0.4787929  0.0000000  0.0000000  0.0000000 #> [367]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [373]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [379] -0.2787463  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [385]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [391]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [397]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [403]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [409]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [415]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [421]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [427]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [433]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [439]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [445]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [451]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [457]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [463]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [469]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [475]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [481]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [487]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [493]  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000  0.0000000 #> [499]  0.0000000  0.0000000"},{"path":"https://nanx.me/msaenet/reference/msaenet-package.html","id":null,"dir":"Reference","previous_headings":"","what":"msaenet: Multi-Step Adaptive Estimation Methods for Sparse Regressions ‚Äî msaenet-package","title":"msaenet: Multi-Step Adaptive Estimation Methods for Sparse Regressions ‚Äî msaenet-package","text":"Multi-step adaptive elastic-net (MSAENet) algorithm feature selection high-dimensional regressions proposed Xiao Xu (2015) doi:10.1080/00949655.2015.1016944 , support multi-step adaptive MCP-net (MSAMNet) multi-step adaptive SCAD-net (MSASNet) methods.","code":""},{"path":[]},{"path":"https://nanx.me/msaenet/reference/msaenet-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"msaenet: Multi-Step Adaptive Estimation Methods for Sparse Regressions ‚Äî msaenet-package","text":"Maintainer: Nan Xiao @nanx.(ORCID) Authors: Qing-Song Xu qsxu@csu.edu.cn","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fn.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Number of False Negative Selections ‚Äî msaenet.fn","title":"Get the Number of False Negative Selections ‚Äî msaenet.fn","text":"Get number false negative selections msaenet model objects, given indices true variables (known).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Number of False Negative Selections ‚Äî msaenet.fn","text":"","code":"msaenet.fn(object, true.idx)"},{"path":"https://nanx.me/msaenet/reference/msaenet.fn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Number of False Negative Selections ‚Äî msaenet.fn","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet. true.idx Vector. Indices true variables.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Number of False Negative Selections ‚Äî msaenet.fn","text":"Number false negative variables model.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fn.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the Number of False Negative Selections ‚Äî msaenet.fn","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Number of False Negative Selections ‚Äî msaenet.fn","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  msaenet.fn(msaenet.fit, 1:5) #> [1] 2"},{"path":"https://nanx.me/msaenet/reference/msaenet.fp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Number of False Positive Selections ‚Äî msaenet.fp","title":"Get the Number of False Positive Selections ‚Äî msaenet.fp","text":"Get number false positive selections msaenet model objects, given indices true variables (known).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Number of False Positive Selections ‚Äî msaenet.fp","text":"","code":"msaenet.fp(object, true.idx)"},{"path":"https://nanx.me/msaenet/reference/msaenet.fp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Number of False Positive Selections ‚Äî msaenet.fp","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet. true.idx Vector. Indices true variables.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Number of False Positive Selections ‚Äî msaenet.fp","text":"Number false positive variables model.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the Number of False Positive Selections ‚Äî msaenet.fp","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.fp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Number of False Positive Selections ‚Äî msaenet.fp","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  msaenet.fp(msaenet.fit, 1:5) #> [1] 5"},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"Multi-Step Adaptive Elastic-Net","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"","code":"msaenet(   x,   y,   family = c(\"gaussian\", \"binomial\", \"poisson\", \"cox\"),   init = c(\"enet\", \"ridge\"),   alphas = seq(0.05, 0.95, 0.05),   tune = c(\"cv\", \"ebic\", \"bic\", \"aic\"),   nfolds = 5L,   rule = c(\"lambda.min\", \"lambda.1se\"),   ebic.gamma = 1,   nsteps = 2L,   tune.nsteps = c(\"max\", \"ebic\", \"bic\", \"aic\"),   ebic.gamma.nsteps = 1,   scale = 1,   lower.limits = -Inf,   upper.limits = Inf,   penalty.factor.init = rep(1, ncol(x)),   seed = 1001,   parallel = FALSE,   verbose = FALSE )"},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"x Data matrix. y Response vector family \"gaussian\", \"binomial\", \"poisson\". family \"cox\", response matrix created Surv. family Model family, can \"gaussian\", \"binomial\", \"poisson\", \"cox\". init Type penalty used initial estimation step. Can \"enet\" \"ridge\". See glmnet details. alphas Vector candidate alphas use cv.glmnet. tune Parameter tuning method estimation step. Possible options \"cv\", \"ebic\", \"bic\", \"aic\". Default \"cv\". nfolds Fold numbers cross-validation tune = \"cv\". rule Lambda selection criterion tune = \"cv\", can \"lambda.min\" \"lambda.1se\". See cv.glmnet details. ebic.gamma Parameter Extended BIC penalizing size model space tune = \"ebic\", default 1. details, see Chen Chen (2008). nsteps Maximum number adaptive estimation steps. least 2, assuming adaptive elastic-net one adaptive estimation step. tune.nsteps Optimal step number selection method (aggregate optimal model step compare). Options include \"max\" (select final-step model directly), compare models using \"ebic\", \"bic\", \"aic\". Default \"max\". ebic.gamma.nsteps Parameter Extended BIC penalizing size model space tune.nsteps = \"ebic\", default 1. scale Scaling factor adaptive weights: weights = coefficients^(-scale). lower.limits Lower limits coefficients. Default -Inf. details, see glmnet. upper.limits Upper limits coefficients. Default Inf. details, see glmnet. penalty.factor.init multiplicative factor penalty applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. make certain variables likely selected, assign smaller value. Default rep(1, ncol(x)). seed Random seed cross-validation fold division. parallel Logical. Enable parallel parameter tuning , default FALSE. enable parallel tuning, load doParallel package run registerDoParallel() number CPU cores calling function. verbose print estimation progress?","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"List model coefficients, glmnet model object, optimal parameter set.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"Nan Xiao Qing-Song Xu. (2015). Multi-step adaptive elastic-net: reducing false positives high-dimensional variable selection. Journal Statistical Computation Simulation 85(18), 3755--3765.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-Step Adaptive Elastic-Net ‚Äî msaenet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  print(msaenet.fit) #> Call: msaenet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.2, 0.8, 0.2),  #>     nsteps = 3L, seed = 1003)  #>   Df     %Dev       Lambda #> 1  8 0.797121 1.219202e+15 msaenet.nzv(msaenet.fit) #> [1]   2   4   5  35 114 269 363 379 msaenet.fp(msaenet.fit, 1:5) #> [1] 5 msaenet.tp(msaenet.fit, 1:5) #> [1] 3 msaenet.pred <- predict(msaenet.fit, dat$x.te) msaenet.rmse(dat$y.te, msaenet.pred) #> [1] 2.839212 plot(msaenet.fit)"},{"path":"https://nanx.me/msaenet/reference/msaenet.mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Absolute Error (MAE) ‚Äî msaenet.mae","title":"Mean Absolute Error (MAE) ‚Äî msaenet.mae","text":"Compute mean absolute error (MAE).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Absolute Error (MAE) ‚Äî msaenet.mae","text":"","code":"msaenet.mae(yreal, ypred)"},{"path":"https://nanx.me/msaenet/reference/msaenet.mae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Absolute Error (MAE) ‚Äî msaenet.mae","text":"yreal Vector. True response. ypred Vector. Predicted response.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Absolute Error (MAE) ‚Äî msaenet.mae","text":"MAE","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mae.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean Absolute Error (MAE) ‚Äî msaenet.mae","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean Squared Error (MSE) ‚Äî msaenet.mse","title":"Mean Squared Error (MSE) ‚Äî msaenet.mse","text":"Compute mean squared error (MSE).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean Squared Error (MSE) ‚Äî msaenet.mse","text":"","code":"msaenet.mse(yreal, ypred)"},{"path":"https://nanx.me/msaenet/reference/msaenet.mse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean Squared Error (MSE) ‚Äî msaenet.mse","text":"yreal Vector. True response. ypred Vector. Predicted response.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean Squared Error (MSE) ‚Äî msaenet.mse","text":"MSE","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.mse.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean Squared Error (MSE) ‚Äî msaenet.mse","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.all.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","title":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","text":"Get indices non-zero variables steps msaenet model objects.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","text":"","code":"msaenet.nzv.all(object)"},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.all.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","text":"List containing indices vectors non-zero variables steps.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.all.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.all.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Indices of Non-Zero Variables in All Steps ‚Äî msaenet.nzv.all","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  msaenet.nzv.all(msaenet.fit) #> [[1]] #>  [1]   1   2   3   4   5   6  33  35  49  73 114 145 183 235 269 334 363 379 441 #> [20] 449 #>  #> [[2]] #>  [1]   2   3   4   5  35  49 114 269 363 379 #>  #> [[3]] #> [1]   2   3   4   5  35 114 269 363 379 #>  #> [[4]] #> [1]   2   4   5  35 114 269 363 379 #>"},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","title":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","text":"Get indices non-zero variables msaenet model objects.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","text":"","code":"msaenet.nzv(object)"},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","text":"Indices vector non-zero variables model.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.nzv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Indices of Non-Zero Variables ‚Äî msaenet.nzv","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  msaenet.nzv(msaenet.fit) #> [1]   2   4   5  35 114 269 363 379  # coefficients of non-zero variables coef(msaenet.fit)[msaenet.nzv(msaenet.fit)] #> [1]  2.1657439  1.7619827  0.8366843  0.8954118 -0.3592967  0.7274414 -0.4787929 #> [8] -0.2787463"},{"path":"https://nanx.me/msaenet/reference/msaenet.rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Root Mean Squared Error (RMSE) ‚Äî msaenet.rmse","title":"Root Mean Squared Error (RMSE) ‚Äî msaenet.rmse","text":"Compute root mean squared error (RMSE).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root Mean Squared Error (RMSE) ‚Äî msaenet.rmse","text":"","code":"msaenet.rmse(yreal, ypred)"},{"path":"https://nanx.me/msaenet/reference/msaenet.rmse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Root Mean Squared Error (RMSE) ‚Äî msaenet.rmse","text":"yreal Vector. True response. ypred Vector. Predicted response.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Root Mean Squared Error (RMSE) ‚Äî msaenet.rmse","text":"RMSE","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmse.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Root Mean Squared Error (RMSE) ‚Äî msaenet.rmse","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmsle.html","id":null,"dir":"Reference","previous_headings":"","what":"Root Mean Squared Logarithmic Error (RMSLE) ‚Äî msaenet.rmsle","title":"Root Mean Squared Logarithmic Error (RMSLE) ‚Äî msaenet.rmsle","text":"Compute root mean squared logarithmic error (RMSLE).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmsle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root Mean Squared Logarithmic Error (RMSLE) ‚Äî msaenet.rmsle","text":"","code":"msaenet.rmsle(yreal, ypred)"},{"path":"https://nanx.me/msaenet/reference/msaenet.rmsle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Root Mean Squared Logarithmic Error (RMSLE) ‚Äî msaenet.rmsle","text":"yreal Vector. True response. ypred Vector. Predicted response.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmsle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Root Mean Squared Logarithmic Error (RMSLE) ‚Äî msaenet.rmsle","text":"RMSLE","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.rmsle.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Root Mean Squared Logarithmic Error (RMSLE) ‚Äî msaenet.rmsle","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.binomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","text":"Generate simulation data benchmarking sparse logistic regression models.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.binomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","text":"","code":"msaenet.sim.binomial(   n = 300,   p = 500,   rho = 0.5,   coef = rep(0.2, 50),   snr = 1,   p.train = 0.7,   seed = 1001 )"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.binomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","text":"n Number observations. p Number variables. rho Correlation base generating correlated variables. coef Vector non-zero coefficients. snr Signal--noise ratio (SNR). p.train Percentage training set. seed Random seed reproducibility.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.binomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","text":"List x.tr, x.te, y.tr, y.te.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.binomial.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.binomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Binomial Response) ‚Äî msaenet.sim.binomial","text":"","code":"dat <- msaenet.sim.binomial(   n = 300, p = 500, rho = 0.6,   coef = rep(1, 10), snr = 3, p.train = 0.7,   seed = 1001 )  dim(dat$x.tr) #> [1] 210 500 dim(dat$x.te) #> [1]  90 500 table(dat$y.tr) #>  #>   0   1  #> 101 109  table(dat$y.te) #>  #>  0  1  #> 48 42"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"Generate simulation data benchmarking sparse Cox regression models.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"","code":"msaenet.sim.cox(   n = 300,   p = 500,   rho = 0.5,   coef = rep(0.2, 50),   snr = 1,   p.train = 0.7,   seed = 1001 )"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"n Number observations. p Number variables. rho Correlation base generating correlated variables. coef Vector non-zero coefficients. snr Signal--noise ratio (SNR). p.train Percentage training set. seed Random seed reproducibility.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"List x.tr, x.te, y.tr, y.te.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"Simon, N., Friedman, J., Hastie, T., & Tibshirani, R. (2011). Regularization Paths Cox's Proportional Hazards Model via Coordinate Descent. Journal Statistical Software, 39(5), 1--13.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.cox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Cox Model) ‚Äî msaenet.sim.cox","text":"","code":"dat <- msaenet.sim.cox(   n = 300, p = 500, rho = 0.6,   coef = rep(1, 10), snr = 3, p.train = 0.7,   seed = 1001 )  dim(dat$x.tr) #> [1] 210 500 dim(dat$x.te) #> [1]  90 500 dim(dat$y.tr) #> [1] 210   2 dim(dat$y.te) #> [1] 90  2"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"Generate simulation data (Gaussian case) following settings Xiao Xu (2015).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"","code":"msaenet.sim.gaussian(   n = 300,   p = 500,   rho = 0.5,   coef = rep(0.2, 50),   snr = 1,   p.train = 0.7,   seed = 1001 )"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"n Number observations. p Number variables. rho Correlation base generating correlated variables. coef Vector non-zero coefficients. snr Signal--noise ratio (SNR). SNR defined $$ \\frac{Var(E(y | X))}{Var(Y - E(y | X))} = \\frac{Var(f(X))}{Var(\\varepsilon)} = \\frac{Var(X^T \\beta)}{Var(\\varepsilon)} = \\frac{Var(\\beta^T \\Sigma \\beta)}{\\sigma^2}. $$ p.train Percentage training set. seed Random seed reproducibility.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"List x.tr, x.te, y.tr, y.te.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"Nan Xiao Qing-Song Xu. (2015). Multi-step adaptive elastic-net: reducing false positives high-dimensional variable selection. Journal Statistical Computation Simulation 85(18), 3755--3765.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.gaussian.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Gaussian Response) ‚Äî msaenet.sim.gaussian","text":"","code":"dat <- msaenet.sim.gaussian(   n = 300, p = 500, rho = 0.6,   coef = rep(1, 10), snr = 3, p.train = 0.7,   seed = 1001 )  dim(dat$x.tr) #> [1] 210 500 dim(dat$x.te) #> [1]  90 500"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","text":"Generate simulation data benchmarking sparse Poisson regression models.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","text":"","code":"msaenet.sim.poisson(   n = 300,   p = 500,   rho = 0.5,   coef = rep(0.2, 50),   snr = 1,   p.train = 0.7,   seed = 1001 )"},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","text":"n Number observations. p Number variables. rho Correlation base generating correlated variables. coef Vector non-zero coefficients. snr Signal--noise ratio (SNR). p.train Percentage training set. seed Random seed reproducibility.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","text":"List x.tr, x.te, y.tr, y.te.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.poisson.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.sim.poisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate Simulation Data for Benchmarking Sparse Regressions (Poisson Response) ‚Äî msaenet.sim.poisson","text":"","code":"dat <- msaenet.sim.poisson(   n = 300, p = 500, rho = 0.6,   coef = rep(1, 10), snr = 3, p.train = 0.7,   seed = 1001 )  dim(dat$x.tr) #> [1] 210 500 dim(dat$x.te) #> [1]  90 500"},{"path":"https://nanx.me/msaenet/reference/msaenet.tp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Number of True Positive Selections ‚Äî msaenet.tp","title":"Get the Number of True Positive Selections ‚Äî msaenet.tp","text":"Get number true positive selections msaenet model objects, given indices true variables (known).","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Number of True Positive Selections ‚Äî msaenet.tp","text":"","code":"msaenet.tp(object, true.idx)"},{"path":"https://nanx.me/msaenet/reference/msaenet.tp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Number of True Positive Selections ‚Äî msaenet.tp","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet. true.idx Vector. Indices true variables.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Number of True Positive Selections ‚Äî msaenet.tp","text":"Number true positive variables model.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the Number of True Positive Selections ‚Äî msaenet.tp","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Number of True Positive Selections ‚Äî msaenet.tp","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  msaenet.tp(msaenet.fit, 1:5) #> [1] 3"},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.glmnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic (parallel) parameter tuning for glmnet models ‚Äî msaenet.tune.glmnet","title":"Automatic (parallel) parameter tuning for glmnet models ‚Äî msaenet.tune.glmnet","text":"Automatic (parallel) parameter tuning glmnet models","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.glmnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic (parallel) parameter tuning for glmnet models ‚Äî msaenet.tune.glmnet","text":"","code":"msaenet.tune.glmnet(   x,   y,   family,   alphas,   tune,   nfolds,   rule,   ebic.gamma,   lower.limits,   upper.limits,   seed,   parallel,   ... )"},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.glmnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic (parallel) parameter tuning for glmnet models ‚Äî msaenet.tune.glmnet","text":"Optimal model object, parameter set, criterion value","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.glmnet.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Automatic (parallel) parameter tuning for glmnet models ‚Äî msaenet.tune.glmnet","text":"Chen, Jiahua, Zehua Chen. (2008). Extended Bayesian information criteria model selection large model spaces. Biometrika 95(3), 759--771.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.glmnet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Automatic (parallel) parameter tuning for glmnet models ‚Äî msaenet.tune.glmnet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.ncvreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic (parallel) parameter tuning for ncvreg models ‚Äî msaenet.tune.ncvreg","title":"Automatic (parallel) parameter tuning for ncvreg models ‚Äî msaenet.tune.ncvreg","text":"Automatic (parallel) parameter tuning ncvreg models","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.ncvreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic (parallel) parameter tuning for ncvreg models ‚Äî msaenet.tune.ncvreg","text":"","code":"msaenet.tune.ncvreg(   x,   y,   family,   penalty,   gammas,   alphas,   tune,   nfolds,   ebic.gamma,   eps,   max.iter,   seed,   parallel,   ... )"},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.ncvreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic (parallel) parameter tuning for ncvreg models ‚Äî msaenet.tune.ncvreg","text":"Optimal model object, parameter set, criterion value","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.ncvreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Automatic (parallel) parameter tuning for ncvreg models ‚Äî msaenet.tune.ncvreg","text":"Chen, Jiahua, Zehua Chen. (2008). Extended Bayesian information criteria model selection large model spaces. Biometrika 95(3), 759--771.","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.ncvreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Automatic (parallel) parameter tuning for ncvreg models ‚Äî msaenet.tune.ncvreg","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.glmnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.glmnet","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.glmnet","text":"Select number adaptive estimation steps","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.glmnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.glmnet","text":"","code":"msaenet.tune.nsteps.glmnet(model.list, tune.nsteps, ebic.gamma.nsteps)"},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.glmnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.glmnet","text":"optimal step number","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.glmnet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.glmnet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.ncvreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.ncvreg","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.ncvreg","text":"Select number adaptive estimation steps","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.ncvreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.ncvreg","text":"","code":"msaenet.tune.nsteps.ncvreg(model.list, tune.nsteps, ebic.gamma.nsteps)"},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.ncvreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.ncvreg","text":"optimal step number","code":""},{"path":"https://nanx.me/msaenet/reference/msaenet.tune.nsteps.ncvreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Select the number of adaptive estimation steps ‚Äî msaenet.tune.nsteps.ncvreg","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msamnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","title":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","text":"Multi-Step Adaptive MCP-Net","code":""},{"path":"https://nanx.me/msaenet/reference/msamnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","text":"","code":"msamnet(   x,   y,   family = c(\"gaussian\", \"binomial\", \"poisson\", \"cox\"),   init = c(\"mnet\", \"ridge\"),   gammas = 3,   alphas = seq(0.05, 0.95, 0.05),   tune = c(\"cv\", \"ebic\", \"bic\", \"aic\"),   nfolds = 5L,   ebic.gamma = 1,   nsteps = 2L,   tune.nsteps = c(\"max\", \"ebic\", \"bic\", \"aic\"),   ebic.gamma.nsteps = 1,   scale = 1,   eps = 1e-04,   max.iter = 10000L,   penalty.factor.init = rep(1, ncol(x)),   seed = 1001,   parallel = FALSE,   verbose = FALSE )"},{"path":"https://nanx.me/msaenet/reference/msamnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","text":"x Data matrix. y Response vector family \"gaussian\", \"binomial\", \"poisson\". family \"cox\", response matrix created Surv. family Model family, can \"gaussian\", \"binomial\", \"poisson\", \"cox\". init Type penalty used initial estimation step. Can \"mnet\" \"ridge\". gammas Vector candidate gammas (concavity parameter) use MCP-Net. Default 3. alphas Vector candidate alphas use MCP-Net. tune Parameter tuning method estimation step. Possible options \"cv\", \"ebic\", \"bic\", \"aic\". Default \"cv\". nfolds Fold numbers cross-validation tune = \"cv\". ebic.gamma Parameter Extended BIC penalizing size model space tune = \"ebic\", default 1. details, see Chen Chen (2008). nsteps Maximum number adaptive estimation steps. least 2, assuming adaptive MCP-net one adaptive estimation step. tune.nsteps Optimal step number selection method (aggregate optimal model step compare). Options include \"max\" (select final-step model directly), compare models using \"ebic\", \"bic\", \"aic\". Default \"max\". ebic.gamma.nsteps Parameter Extended BIC penalizing size model space tune.nsteps = \"ebic\", default 1. scale Scaling factor adaptive weights: weights = coefficients^(-scale). eps Convergence threshhold use MCP-net. max.iter Maximum number iterations use MCP-net. penalty.factor.init multiplicative factor penalty applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. make certain variables likely selected, assign smaller value. Default rep(1, ncol(x)). seed Random seed cross-validation fold division. parallel Logical. Enable parallel parameter tuning , default FALSE. enable parallel tuning, load doParallel package run registerDoParallel() number CPU cores calling function. verbose print estimation progress?","code":""},{"path":"https://nanx.me/msaenet/reference/msamnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","text":"List model coefficients, ncvreg model object, optimal parameter set.","code":""},{"path":"https://nanx.me/msaenet/reference/msamnet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msamnet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-Step Adaptive MCP-Net ‚Äî msamnet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msamnet.fit <- msamnet(   dat$x.tr, dat$y.tr,   alphas = seq(0.3, 0.9, 0.3),   nsteps = 3L, seed = 1003 )  print(msamnet.fit) #> Call: msamnet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.3, 0.9, 0.3),  #>     nsteps = 3L, seed = 1003)  #>   Df    Lambda Gamma Alpha #> 1  3 0.4095215     3   0.9 msaenet.nzv(msamnet.fit) #> [1]  2  4 35 msaenet.fp(msamnet.fit, 1:5) #> [1] 1 msaenet.tp(msamnet.fit, 1:5) #> [1] 2 msamnet.pred <- predict(msamnet.fit, dat$x.te) msaenet.rmse(dat$y.te, msamnet.pred) #> [1] 2.909138 plot(msamnet.fit)"},{"path":"https://nanx.me/msaenet/reference/msasnet.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","title":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","text":"Multi-Step Adaptive SCAD-Net","code":""},{"path":"https://nanx.me/msaenet/reference/msasnet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","text":"","code":"msasnet(   x,   y,   family = c(\"gaussian\", \"binomial\", \"poisson\", \"cox\"),   init = c(\"snet\", \"ridge\"),   gammas = 3.7,   alphas = seq(0.05, 0.95, 0.05),   tune = c(\"cv\", \"ebic\", \"bic\", \"aic\"),   nfolds = 5L,   ebic.gamma = 1,   nsteps = 2L,   tune.nsteps = c(\"max\", \"ebic\", \"bic\", \"aic\"),   ebic.gamma.nsteps = 1,   scale = 1,   eps = 1e-04,   max.iter = 10000L,   penalty.factor.init = rep(1, ncol(x)),   seed = 1001,   parallel = FALSE,   verbose = FALSE )"},{"path":"https://nanx.me/msaenet/reference/msasnet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","text":"x Data matrix. y Response vector family \"gaussian\", \"binomial\", \"poisson\". family \"cox\", response matrix created Surv. family Model family, can \"gaussian\", \"binomial\", \"poisson\", \"cox\". init Type penalty used initial estimation step. Can \"snet\" \"ridge\". gammas Vector candidate gammas (concavity parameter) use SCAD-Net. Default 3.7. alphas Vector candidate alphas use SCAD-Net. tune Parameter tuning method estimation step. Possible options \"cv\", \"ebic\", \"bic\", \"aic\". Default \"cv\". nfolds Fold numbers cross-validation tune = \"cv\". ebic.gamma Parameter Extended BIC penalizing size model space tune = \"ebic\", default 1. details, see Chen Chen (2008). nsteps Maximum number adaptive estimation steps. least 2, assuming adaptive SCAD-net one adaptive estimation step. tune.nsteps Optimal step number selection method (aggregate optimal model step compare). Options include \"max\" (select final-step model directly), compare models using \"ebic\", \"bic\", \"aic\". Default \"max\". ebic.gamma.nsteps Parameter Extended BIC penalizing size model space tune.nsteps = \"ebic\", default 1. scale Scaling factor adaptive weights: weights = coefficients^(-scale). eps Convergence threshhold use SCAD-net. max.iter Maximum number iterations use SCAD-net. penalty.factor.init multiplicative factor penalty applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. make certain variables likely selected, assign smaller value. Default rep(1, ncol(x)). seed Random seed cross-validation fold division. parallel Logical. Enable parallel parameter tuning , default FALSE. enable parallel tuning, load doParallel package run registerDoParallel() number CPU cores calling function. verbose print estimation progress?","code":""},{"path":"https://nanx.me/msaenet/reference/msasnet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","text":"List model coefficients, ncvreg model object, optimal parameter set.","code":""},{"path":"https://nanx.me/msaenet/reference/msasnet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/msasnet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-Step Adaptive SCAD-Net ‚Äî msasnet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msasnet.fit <- msasnet(   dat$x.tr, dat$y.tr,   alphas = seq(0.3, 0.9, 0.3),   nsteps = 3L, seed = 1003 )  print(msasnet.fit) #> Call: msasnet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.3, 0.9, 0.3),  #>     nsteps = 3L, seed = 1003)  #>   Df    Lambda Gamma Alpha #> 1  2 0.4417073   3.7   0.9 msaenet.nzv(msasnet.fit) #> [1] 2 4 msaenet.fp(msasnet.fit, 1:5) #> [1] 0 msaenet.tp(msasnet.fit, 1:5) #> [1] 2 msasnet.pred <- predict(msasnet.fit, dat$x.te) msaenet.rmse(dat$y.te, msasnet.pred) #> [1] 2.724265 plot(msasnet.fit)"},{"path":"https://nanx.me/msaenet/reference/plot.msaenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot msaenet Model Objects ‚Äî plot.msaenet","title":"Plot msaenet Model Objects ‚Äî plot.msaenet","text":"Plot msaenet model objects.","code":""},{"path":"https://nanx.me/msaenet/reference/plot.msaenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot msaenet Model Objects ‚Äî plot.msaenet","text":"","code":"# S3 method for msaenet plot(   x,   type = c(\"coef\", \"criterion\", \"dotplot\"),   nsteps = NULL,   highlight = TRUE,   col = NULL,   label = FALSE,   label.vars = NULL,   label.pos = 2,   label.offset = 0.3,   label.cex = 0.7,   label.srt = 90,   xlab = NULL,   ylab = NULL,   abs = FALSE,   ... )"},{"path":"https://nanx.me/msaenet/reference/plot.msaenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot msaenet Model Objects ‚Äî plot.msaenet","text":"x object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet. type Plot type, \"coef\" coefficient path plot across estimation steps; \"criterion\" scree plot model evaluation criterion used (CV error, AIC, BIC, EBIC); \"dotplot\" Cleveland dot plot coefficients estimated model optimal step. nsteps Maximum number estimation steps plot. Default plot steps. highlight highlight \"optimal\" step according criterion? Default TRUE. col Color palette use coefficient paths. NULL, default color palette assigned. label label non-zero variables optimal step coefficient plot dot plot? Default FALSE. TRUE label.vars = NULL, index non-zero variables used labels. label.vars Labels use variables label = \"TRUE\". label.pos Position labels. See argument pos text details. label.offset Offset labels. See argument offset text details. label.cex Character expansion factor labels. See argument cex text details. label.srt Label rotation degrees Cleveland dot plot. Default 90. See argument srt par details. xlab Title x axis. NULL, use default title. ylab Title y axis. NULL, use default title. abs plot absolute values coefficients instead raw coefficients Cleveland dot plot? Default FALSE. ... parameters (used).","code":""},{"path":"https://nanx.me/msaenet/reference/plot.msaenet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot msaenet Model Objects ‚Äî plot.msaenet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/plot.msaenet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot msaenet Model Objects ‚Äî plot.msaenet","text":"","code":"# \\donttest{ dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 5L, tune.nsteps = \"bic\",   seed = 1002 )  plot(fit) plot(fit, label = TRUE)  plot(fit, label = TRUE, nsteps = 5)  plot(fit, type = \"criterion\")  plot(fit, type = \"criterion\", nsteps = 5)  plot(fit, type = \"dotplot\", label = TRUE)  plot(fit, type = \"dotplot\", label = TRUE, abs = TRUE)  # }"},{"path":"https://nanx.me/msaenet/reference/predict.msaenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","title":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","text":"Make predictions new data msaenet model object.","code":""},{"path":"https://nanx.me/msaenet/reference/predict.msaenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","text":"","code":"# S3 method for msaenet predict(object, newx, ...)"},{"path":"https://nanx.me/msaenet/reference/predict.msaenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","text":"object object class msaenet produced aenet, amnet, asnet, msaenet, msamnet, msasnet. newx New data predict . ... Additional parameters, particularly prediction type predict.glmnet, predict.ncvreg, predict.ncvsurv.","code":""},{"path":"https://nanx.me/msaenet/reference/predict.msaenet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","text":"Numeric matrix predicted values.","code":""},{"path":"https://nanx.me/msaenet/reference/predict.msaenet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/predict.msaenet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make Predictions from an msaenet Model ‚Äî predict.msaenet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  msaenet.pred <- predict(msaenet.fit, dat$x.te) msaenet.rmse(dat$y.te, msaenet.pred) #> [1] 2.839212"},{"path":"https://nanx.me/msaenet/reference/print.msaenet.html","id":null,"dir":"Reference","previous_headings":"","what":"Print msaenet Model Information ‚Äî print.msaenet","title":"Print msaenet Model Information ‚Äî print.msaenet","text":"Print msaenet model objects (currently, printing model information final step).","code":""},{"path":"https://nanx.me/msaenet/reference/print.msaenet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print msaenet Model Information ‚Äî print.msaenet","text":"","code":"# S3 method for msaenet print(x, ...)"},{"path":"https://nanx.me/msaenet/reference/print.msaenet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print msaenet Model Information ‚Äî print.msaenet","text":"x object class msaenet. ... Additional parameters print (used).","code":""},{"path":"https://nanx.me/msaenet/reference/print.msaenet.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print msaenet Model Information ‚Äî print.msaenet","text":"Nan Xiao <https://nanx.>","code":""},{"path":"https://nanx.me/msaenet/reference/print.msaenet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print msaenet Model Information ‚Äî print.msaenet","text":"","code":"dat <- msaenet.sim.gaussian(   n = 150, p = 500, rho = 0.6,   coef = rep(1, 5), snr = 2, p.train = 0.7,   seed = 1001 )  msaenet.fit <- msaenet(   dat$x.tr, dat$y.tr,   alphas = seq(0.2, 0.8, 0.2),   nsteps = 3L, seed = 1003 )  print(msaenet.fit) #> Call: msaenet(x = dat$x.tr, y = dat$y.tr, alphas = seq(0.2, 0.8, 0.2),  #>     nsteps = 3L, seed = 1003)  #>   Df     %Dev       Lambda #> 1  8 0.797121 1.219202e+15"},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-311","dir":"Changelog","previous_headings":"","what":"msaenet 3.1.1","title":"msaenet 3.1.1","text":"CRAN release: 2024-03-04","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-3-1-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 3.1.1","text":"Use proper, three-component version number following Semantic Versioning. Fix warnings single lambda (#11). Fix ‚Äúlost braces‚Äù check notes r-devel check notes LazyData. Fix code linting issues. Use GitHub Actions build pkgdown site.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-31","dir":"Changelog","previous_headings":"","what":"msaenet 3.1","title":"msaenet 3.1","text":"CRAN release: 2019-05-17","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-3-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 3.1","text":"Added detailed signal--noise ratio (SNR) definition msaenet.sim.gaussian(). Updated example code vignette make work better recent version glmnet (2.0-16). Updated GitHub repository links due handle change. Updated vignette style.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-30","dir":"Changelog","previous_headings":"","what":"msaenet 3.0","title":"msaenet 3.0","text":"CRAN release: 2018-12-14","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 3.0","text":"Added new argument penalty.factor.init support customized penalty factor applied coefficient initial estimation step. useful incorporating prior information variable weights, example, emphasizing specific clinical variables. thank Xin Wang University Michigan feedback [#4].","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-29","dir":"Changelog","previous_headings":"","what":"msaenet 2.9","title":"msaenet 2.9","text":"CRAN release: 2018-05-14","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-9","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.9","text":"New URL documentation website: https://nanx./msaenet/.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-28","dir":"Changelog","previous_headings":"","what":"msaenet 2.8","title":"msaenet 2.8","text":"CRAN release: 2018-01-05","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-2-8","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 2.8","text":"Added Cleveland dot plot option type = \"dotplot\" plot.msaenet(). plot offers direct visualization model coefficients optimal step.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-27","dir":"Changelog","previous_headings":"","what":"msaenet 2.7","title":"msaenet 2.7","text":"CRAN release: 2017-09-24","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"bug-fixes-2-7","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"msaenet 2.7","text":"Fixed missing arguments issue init = \"ridge\".","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-26","dir":"Changelog","previous_headings":"","what":"msaenet 2.6","title":"msaenet 2.6","text":"CRAN release: 2017-04-24","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-6","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.6","text":"Added two arguments lower.limits upper.limits support coefficient constraints aenet() msaenet() [#1].","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-25","dir":"Changelog","previous_headings":"","what":"msaenet 2.5","title":"msaenet 2.5","text":"CRAN release: 2017-03-25","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-5","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.5","text":"Better code indentation style. Update gallery images README.md.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-24","dir":"Changelog","previous_headings":"","what":"msaenet 2.4","title":"msaenet 2.4","text":"CRAN release: 2017-02-18","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-4","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.4","text":"Improved graphical details coefficient path plots, following general graphic style ESL (Elements Statistical Learning) book. options available plot.msaenet() extra flexibility: now possible set important properties label appearance position, offset, font size, axis titles via new arguments label.pos, label.offset, label.cex, xlab, ylab.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-23","dir":"Changelog","previous_headings":"","what":"msaenet 2.3","title":"msaenet 2.3","text":"CRAN release: 2017-02-10","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-3","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.3","text":"Reduced model saturation cases improved speed initialization step MCP-net SCAD-net based models init = \"ridge\", using ridge estimation implementation glmnet. benefit, now aligned baseline comparison elastic-net based models MCP-net/SCAD-net based models init = \"ridge\". Style improvements code examples: reduced whitespace new formatting scheme.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-22","dir":"Changelog","previous_headings":"","what":"msaenet 2.2","title":"msaenet 2.2","text":"CRAN release: 2017-02-02","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-2-2","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 2.2","text":"Added BIC, EBIC, AIC addition k-fold cross-validation model selection. Added new arguments tune tune.nsteps controls selecting optimal model step, optimal model among steps (.e.¬†optimal step). Added arguments ebic.gamma ebic.gamma.nsteps control EBIC tuning parameter, ebic specified tune tune.nsteps. Redesigned plot function: now supports two types plots (coefficient path, screeplot optimal step selection criterion), optimal step highlighting, variable labeling, color palette customization. See ?plot.msaenet details.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-2","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.2","text":"Renamed previous argument gamma (scaling factor adaptive weights) scale avoid possible confusion. Reset default values candidate concavity parameter gammas 3.7 SCAD-net 3 MCP-net. Unified supported model family model types \"gaussian\", \"binomial\", \"poisson\", \"cox\".","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-21","dir":"Changelog","previous_headings":"","what":"msaenet 2.1","title":"msaenet 2.1","text":"CRAN release: 2017-01-15","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-2-1","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 2.1","text":"Added functions msaenet.sim.binomial(), msaenet.sim.poisson(), msaenet.sim.cox() generate simulation data logistic, Poisson, Cox regression models. Added function msaenet.fn() computing number false negative selections msaenet models. Added function msaenet.mse() computing mean squared error (MSE).","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.1","text":"Speed improvements msaenet.sim.gaussian() vectorization generating correlation matrices. Added parameters max.iter epsilon MCP-net SCAD-net related functions finer control convergence criterion. default, max.iter = 10000 epsilon = 1e-4.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-20","dir":"Changelog","previous_headings":"","what":"msaenet 2.0","title":"msaenet 2.0","text":"CRAN release: 2017-01-05","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 2.0","text":"Added support adaptive MCP-net. See ?amnet details. Added support adaptive SCAD-net. See ?asnet details. Added support multi-step adaptive MCP-net (MSAMNet). See ?msamnet details. Added support multi-step adaptive SCAD-net (MSASNet). See ?msasnet details. Added msaenet.nzv.() displaying indices non-zero variables adaptive estimation steps.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-2-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 2.0","text":"flexible predict.msaenet method allowing users specify prediction type.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-11","dir":"Changelog","previous_headings":"","what":"msaenet 1.1","title":"msaenet 1.1","text":"CRAN release: 2016-12-29","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 1.1","text":"Added method coef extracting model coefficients. See ?coef.msaenet details.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"improvements-1-1","dir":"Changelog","previous_headings":"","what":"Improvements","title":"msaenet 1.1","text":"New documentation website generated pkgdown, full set function documentation vignettes available. Added Windows continuous integration support using AppVeyor.","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"msaenet-10","dir":"Changelog","previous_headings":"","what":"msaenet 1.0","title":"msaenet 1.0","text":"CRAN release: 2016-09-20","code":""},{"path":"https://nanx.me/msaenet/news/index.html","id":"new-features-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"msaenet 1.0","text":"Initial version msaenet package","code":""}]
